# Exercise: Working With Files On Hadoop HDFS

1. Download Apache Hadoop
2. Start a single-node HDFS cluster
3. Develop a Spark SQL application
    1. Loads a file from HDFS into a DataFrame
    2. Transforms the dataset
    3. Saves the dataset to HDFS

Duration: 45 mins